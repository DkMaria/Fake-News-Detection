{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_UNDER_FN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqzxvS5kniiqXqYtT6uRSb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DkMaria/Fake-News-Detection/blob/main/BERT_UNDER_FN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAsdqfvfdBnb"
      },
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlvnDTcQdFwT",
        "outputId": "6024bbe6-619b-4b7e-9de6-47f666184748"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNAS8PQQdIPe",
        "outputId": "e515f46b-5093-4f16-853c-01ffb1ab0261"
      },
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3aMzzikdKJh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import gc #garbage collector for gpu memory \n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32htci44dMp-",
        "outputId": "6a864d8b-6f5a-4be8-dee6-077cbc13d184"
      },
      "source": [
        "# read csv files which contains all TRUE claims\n",
        "true = pd.read_csv('/content/drive/MyDrive/true28.csv', delimiter=\",\")\n",
        "df_true = pd.DataFrame(true, columns=['headline', 'text', 'keywords', 'datePublished', 'ratingName'])\n",
        "print('TRUE: ', df_true)\n",
        "print(len(df_true)) # 4448\n",
        "print(df_true.head())\n",
        "\n",
        "# read csv files which contains all FALSE claims\n",
        "false = pd.read_csv('/content/drive/MyDrive/false05.csv', delimiter=\",\", encoding='mac_roman')\n",
        "df_false = pd.DataFrame(false, columns=['headline', 'text', 'keywords', 'datePublished', 'ratingName'])\n",
        "print('FALSE: ', df_false)\n",
        "print(len(df_false)) # \n",
        "print(df_false.head())\n",
        "\n",
        "df_true['label'] = 0\n",
        "df_false['label'] = 1\n",
        "data = pd.concat([df_true, df_false])\n",
        "labels = data['label']\n",
        "\n",
        "# shuffle the dataset\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "target = data['label'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRUE:                                                 headline  ... ratingName\n",
            "0                   Fiorina: Trump's abortion flip-flop  ...       True\n",
            "1     Sean Hannity says Barack Obama's jobs bill cre...  ...       True\n",
            "2                          \"\"Executive\"\" makes it right  ...       True\n",
            "3                 Chase Bank Won’t Allow Cash Deposits?  ...       True\n",
            "4                            Shackelford Prayer Request  ...       True\n",
            "...                                                 ...  ...        ...\n",
            "4108                                        Moose Story  ...       True\n",
            "4109  Rand Paul says federal spending has risen to 2...  ...       True\n",
            "4110                                    Vieques Closure  ...       True\n",
            "4111          DeKalb CEO says he wields a big budget ax  ...       True\n",
            "4112               Dewitos: Doritos Flavor Mountain Dew  ...       True\n",
            "\n",
            "[4113 rows x 5 columns]\n",
            "4113\n",
            "                                            headline  ... ratingName\n",
            "0                Fiorina: Trump's abortion flip-flop  ...       True\n",
            "1  Sean Hannity says Barack Obama's jobs bill cre...  ...       True\n",
            "2                       \"\"Executive\"\" makes it right  ...       True\n",
            "3              Chase Bank Won’t Allow Cash Deposits?  ...       True\n",
            "4                         Shackelford Prayer Request  ...       True\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "FALSE:                                                 headline  ... ratingName\n",
            "0                           Who Stripped Jessica Rabbit  ...      False\n",
            "1            Translation of Turkish Airline Regulations  ...      False\n",
            "2     The health care law a \"\"job killer\"\"? The evid...  ...      False\n",
            "3     FALSE: Trump Supporters Misspelled His Name wi...  ...      False\n",
            "4                      Tom Daschle Pledge of Allegiance  ...      False\n",
            "...                                                 ...  ...        ...\n",
            "9995  Rauner's Chicago schools \"\"bailout\"\" claim roo...  ...      False\n",
            "9996  Did President Trump Sign an Executive Order Na...  ...      False\n",
            "9997                                One Pound of Mofeen  ...      False\n",
            "9998  No, Trump didn't say illegal immigration has b...  ...      False\n",
            "9999   Is This a Poster for a New ‚ÄòTwilight‚Äô Movie?  ...      False\n",
            "\n",
            "[10000 rows x 5 columns]\n",
            "10000\n",
            "                                            headline  ... ratingName\n",
            "0                        Who Stripped Jessica Rabbit  ...      False\n",
            "1         Translation of Turkish Airline Regulations  ...      False\n",
            "2  The health care law a \"\"job killer\"\"? The evid...  ...      False\n",
            "3  FALSE: Trump Supporters Misspelled His Name wi...  ...      False\n",
            "4                   Tom Daschle Pledge of Allegiance  ...      False\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "vBmxf9SidP_v",
        "outputId": "faffc90a-8ba5-49ae-8bee-432fc4dc479a"
      },
      "source": [
        "from collections import Counter\n",
        "print(Counter(data['ratingName'].values))\n",
        "\n",
        "# class count\n",
        "true_count, false_count = data['label'].value_counts()\n",
        "\n",
        "# Separate class\n",
        "true = data[data['label'] == 0] #true claims\n",
        "false = data[data['label'] == 1]# print the shape of the class #false claims\n",
        "print('true 0:', true.shape)\n",
        "print('false 1:', false.shape)\n",
        "\n",
        "\n",
        "'''Undersampling can be defined as removing some observations of the majority class. This is done until the majority and \n",
        "minority class is balanced out'''\n",
        "false_under = false.sample(false_count)\n",
        "#print(class_1_under)\n",
        "\n",
        "test_under = pd.concat([false_under, true], axis=0)\n",
        "\n",
        "print(\"total class of 1 and 0:\",test_under['label'].value_counts())# plot the count after under-sampeling\n",
        "test_under['label'].value_counts().plot(kind='bar', title='count (target)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({False: 10000, True: 4113})\n",
            "true 0: (4113, 6)\n",
            "false 1: (10000, 6)\n",
            "total class of 1 and 0: 1    4113\n",
            "0    4113\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4f44e5910>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bELm3pBqdavQ"
      },
      "source": [
        "target = test_under['label']\n",
        "\n",
        "data = test_under.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOal2jo1eH8j"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(test_under['text'], target, test_size=0.2, random_state=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQGWd3_fcIN"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBZS9v0wfODR"
      },
      "source": [
        "train_txts = X_train\n",
        "train_lbels = y_train\n",
        "\n",
        "test_txts = X_test\n",
        "test_lbels = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW2kYpQ3gSLf"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eYnqVHHgX3l"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from pytorch_pretrained_bert import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3bzUaf0gd63",
        "outputId": "1385143a-0910-426b-c73f-9954853e93a5"
      },
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 686439.20B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfU5rak4giqF",
        "outputId": "6fc76114-6098-40e5-a523-4ab6f8aeccb1"
      },
      "source": [
        "len(train_txts), len(train_lbels), len(test_txts), len(test_lbels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6580, 6580, 1646, 1646)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVOasQxSgkEI"
      },
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_txts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_txts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1NppGs_gn5-"
      },
      "source": [
        "'''Convert each token in each news to an id as present in the tokenizer vocabulary. If there’s a \n",
        "   token that is not present in the vocabulary, the tokenizer will use the special [UNK] token and\n",
        "   use its id'''\n",
        "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
        "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54XGY5OJgq5U"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EOnUYvVgtC3"
      },
      "source": [
        "'''we need to pad our input so it will have the same size of 512. It means that for any review that \n",
        "   is shorter than 512 tokens, we’ll add zeros to reach 512 tokens'''\n",
        "\n",
        "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhzv0hl_gxig"
      },
      "source": [
        "'''Our target variable is currently a list of 0 and 1. We’ll convert it to numpy arrays of\n",
        "   booleans'''\n",
        "\n",
        "train_y = np.array(train_lbels) \n",
        "test_y = np.array(test_lbels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KiQtRTkg1up",
        "outputId": "1446d8d4-620b-4f03-8885-c2d1ea2e35d0"
      },
      "source": [
        "type(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhCdKVJjg4h-"
      },
      "source": [
        "from pytorch_pretrained_bert import BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dII0ShgWg7Ct"
      },
      "source": [
        "'''Create our BERT classifier which contains an ‘initialization’ method and a ‘forward’ method that \n",
        "   returns token probabilities'''\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pakhEmZ2g9wT",
        "outputId": "0dde62c9-33a1-4367-ef2a-1c49501dcf78"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e1-UixcXhAJM",
        "outputId": "3a403de9-8198-4834-cef6-632029f6d2ac"
      },
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.0M'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tSVB3zhC2v",
        "outputId": "3047a581-1f78-47a1-c0c9-290e2d77afbd"
      },
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf = bert_clf.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:13<00:00, 30508355.03B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RXFya7v8hSoD",
        "outputId": "450ce567-bf67-4890-9908-3fd71e974759"
      },
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'439.065088M'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdUEc9NDhVZf",
        "outputId": "4cba13f6-e0ea-4518-cff2-1c7b01380bb7"
      },
      "source": [
        "x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
        "y, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\n",
        "x.shape, y.shape, pooled.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 512]), torch.Size([3, 512, 768]), torch.Size([3, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ro4Zvy_BhYzX",
        "outputId": "b1ec8489-3cd6-4c31-913f-49557922be99"
      },
      "source": [
        "y, x, pooled = None, None, None\n",
        "torch.cuda.empty_cache()\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3568.20736M'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6WSPX2bhcx-"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRY7_0k6hgii"
      },
      "source": [
        "'''Generate training and testing masks'''\n",
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "'''Generate token tensors for training and testing'''\n",
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "'''Prepare data loaders'''\n",
        "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
        "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
        "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAyeuMUUhp11"
      },
      "source": [
        "param_optimizer = list(bert_clf.sigmoid.named_parameters()) \n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG4mx_hxhs5j"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn8t6_PehxXc"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GbXVNlhhzdv"
      },
      "source": [
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        loss_func = nn.BCELoss()\n",
        "\n",
        "        batch_loss = loss_func(logits, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        #clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(X_train) / BATCH_SIZE, train_loss / (step_num + 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp2EnjPrj94d"
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        loss = loss_func(logits, labels)\n",
        "        numpy_logits = logits.cpu().detach().numpy()\n",
        "        \n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "        all_logits += list(numpy_logits[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBUyvQgvkxmm",
        "outputId": "34ed9af2-28f5-49b7-891f-141365f002ed"
      },
      "source": [
        "np.mean(bert_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3784933171324423"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bifTFzkwk2Od",
        "outputId": "f1c7263c-779d-43b8-cad9-fcfa16e6f47d"
      },
      "source": [
        "print(classification_report(test_y, bert_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.85      0.78       862\n",
            "           1       0.79      0.63      0.70       784\n",
            "\n",
            "    accuracy                           0.74      1646\n",
            "   macro avg       0.75      0.74      0.74      1646\n",
            "weighted avg       0.75      0.74      0.74      1646\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT2_FAKE_NEWS.ipynb",
      "provenance": [],
      "mount_file_id": "1jKXHWVLQMHrXra0EKCtHzQ90M0Z5AnZM",
      "authorship_tag": "ABX9TyOryShrq5JoF0rA4pKTapj7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DkMaria/Fake-News-Detection/blob/main/BERT2_FAKE_NEWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbKmuP4xGiju"
      },
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUHPsdnJ7Tci",
        "outputId": "5e7731d9-e08d-4b36-f9e9-6852fdf6491f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXCl76HD7d6C",
        "outputId": "8b4743fb-2f4d-4aa7-bad5-b052c5c1fd46"
      },
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Ij1_o-7hpr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import gc #garbage collector for gpu memory \n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KpUVxBS7kVH",
        "outputId": "17041a29-4f20-4357-85f1-62064e059f8c"
      },
      "source": [
        "# read csv files which contains all TRUE claims\n",
        "true = pd.read_csv('/content/drive/MyDrive/true28.csv', delimiter=\",\")\n",
        "df_true = pd.DataFrame(true, columns=['headline', 'text', 'keywords', 'datePublished', 'ratingName'])\n",
        "print('TRUE: ', df_true)\n",
        "print(len(df_true)) # 4448\n",
        "print(df_true.head())\n",
        "\n",
        "# read csv files which contains all FALSE claims\n",
        "false = pd.read_csv('/content/drive/MyDrive/false05.csv', delimiter=\",\", encoding='mac_roman')\n",
        "df_false = pd.DataFrame(false, columns=['headline', 'text', 'keywords', 'datePublished', 'ratingName'])\n",
        "print('FALSE: ', df_false)\n",
        "print(len(df_false)) # \n",
        "print(df_false.head())\n",
        "\n",
        "df_true['label'] = 0\n",
        "df_false['label'] = 1\n",
        "data = pd.concat([df_true, df_false])\n",
        "labels = data['label']\n",
        "\n",
        "# shuffle the dataset\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "target = data['label'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRUE:                                                 headline  ... ratingName\n",
            "0                   Fiorina: Trump's abortion flip-flop  ...       True\n",
            "1     Sean Hannity says Barack Obama's jobs bill cre...  ...       True\n",
            "2                          \"\"Executive\"\" makes it right  ...       True\n",
            "3                 Chase Bank Won’t Allow Cash Deposits?  ...       True\n",
            "4                            Shackelford Prayer Request  ...       True\n",
            "...                                                 ...  ...        ...\n",
            "4108                                        Moose Story  ...       True\n",
            "4109  Rand Paul says federal spending has risen to 2...  ...       True\n",
            "4110                                    Vieques Closure  ...       True\n",
            "4111          DeKalb CEO says he wields a big budget ax  ...       True\n",
            "4112               Dewitos: Doritos Flavor Mountain Dew  ...       True\n",
            "\n",
            "[4113 rows x 5 columns]\n",
            "4113\n",
            "                                            headline  ... ratingName\n",
            "0                Fiorina: Trump's abortion flip-flop  ...       True\n",
            "1  Sean Hannity says Barack Obama's jobs bill cre...  ...       True\n",
            "2                       \"\"Executive\"\" makes it right  ...       True\n",
            "3              Chase Bank Won’t Allow Cash Deposits?  ...       True\n",
            "4                         Shackelford Prayer Request  ...       True\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "FALSE:                                                 headline  ... ratingName\n",
            "0                           Who Stripped Jessica Rabbit  ...      False\n",
            "1            Translation of Turkish Airline Regulations  ...      False\n",
            "2     The health care law a \"\"job killer\"\"? The evid...  ...      False\n",
            "3     FALSE: Trump Supporters Misspelled His Name wi...  ...      False\n",
            "4                      Tom Daschle Pledge of Allegiance  ...      False\n",
            "...                                                 ...  ...        ...\n",
            "9995  Rauner's Chicago schools \"\"bailout\"\" claim roo...  ...      False\n",
            "9996  Did President Trump Sign an Executive Order Na...  ...      False\n",
            "9997                                One Pound of Mofeen  ...      False\n",
            "9998  No, Trump didn't say illegal immigration has b...  ...      False\n",
            "9999   Is This a Poster for a New ‚ÄòTwilight‚Äô Movie?  ...      False\n",
            "\n",
            "[10000 rows x 5 columns]\n",
            "10000\n",
            "                                            headline  ... ratingName\n",
            "0                        Who Stripped Jessica Rabbit  ...      False\n",
            "1         Translation of Turkish Airline Regulations  ...      False\n",
            "2  The health care law a \"\"job killer\"\"? The evid...  ...      False\n",
            "3  FALSE: Trump Supporters Misspelled His Name wi...  ...      False\n",
            "4                   Tom Daschle Pledge of Allegiance  ...      False\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRJJJkJD8Q6X",
        "outputId": "2c4fb2a6-d189-46d8-e697-85367b06a9c8"
      },
      "source": [
        "from collections import Counter\n",
        "print(Counter(data['ratingName'].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({False: 10000, True: 4113})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw1oghvA9JU5"
      },
      "source": [
        "# class count\n",
        "true_count, false_count = data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnKlI1zh9ZLx",
        "outputId": "e4a553ba-6af1-456e-d53c-034982e39cb8"
      },
      "source": [
        "# Separate class\n",
        "true = data[data['label'] == 0] #true claims\n",
        "false = data[data['label'] == 1]# print the shape of the class #false claims\n",
        "print('true 0:', true.shape)\n",
        "print('false 1:', false.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true 0: (4113, 6)\n",
            "false 1: (10000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "UF0Xu2xS8i2_",
        "outputId": "a731a873-ee32-4aee-841b-aa3ea1efcf22"
      },
      "source": [
        "'''Oversampling can be defined as adding more copies to the minority class. Oversampling can be a good choice when \n",
        "   you don’t have a ton of data to work with. A con to consider when undersampling is that it can cause overfitting \n",
        "   and poor generalization to your test set'''\n",
        "'''true_over = true.sample(true_count, replace=True)\n",
        "\n",
        "test_over = pd.concat([true_over, false], axis=0)\n",
        "\n",
        "print(\"total class of 1 and 0:\",test_over['label'].value_counts())# plot the count after under-sampeling\n",
        "test_over['label'].value_counts().plot(kind='bar', title='count (target)')'''\n",
        "\n",
        "\n",
        "'''Undersampling can be defined as removing some observations of the majority class. This is done until the majority and \n",
        "minority class is balanced out'''\n",
        "false_under = false.sample(false_count)\n",
        "#print(class_1_under)\n",
        "\n",
        "test_under = pd.concat([false_under, true], axis=0)\n",
        "\n",
        "print(\"total class of 1 and 0:\",test_under['label'].value_counts())# plot the count after under-sampeling\n",
        "test_under['label'].value_counts().plot(kind='bar', title='count (target)')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total class of 1 and 0: 1    4113\n",
            "0    4113\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50316b7210>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCowspLoB56V"
      },
      "source": [
        "target = test_over['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRQex9DfaqOm"
      },
      "source": [
        "data = test_under.sample(frac=1)\n",
        "''' split dataset to 1000, 100 --> gives accuracy 0.72\n",
        "train_data = data.head(1000)\n",
        "test_data = data.tail(100)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VddlQN0_baIL"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RZ1YJyPdy5t",
        "outputId": "7583432a-b694-44de-e8c6-22a4a4366ccd"
      },
      "source": [
        "type(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpqxdM9Lb7bN"
      },
      "source": [
        "train_txts = train_data['text']\n",
        "train_lbels = train_data['label']\n",
        "\n",
        "test_txts = test_data['text']\n",
        "test_lbels = test_data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJT8ctkhBGnU",
        "outputId": "4840e176-864a-42c7-87fd-c6509fda1c48"
      },
      "source": [
        "'''print(type(test_text))\n",
        "print(type(test_labels))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI7lVsXZNp5I"
      },
      "source": [
        "'''test_text = pd.Series(test_text, name = \"Text\")\n",
        "test_label = pd.Series(test_labels, name = \"Label\")\n",
        "\n",
        "test_data = pd.concat([test_text, test_label.astype(int)], axis = 1)\n",
        "print(test_data)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TR7XVieCf-B"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "670dPZfOCakm"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from pytorch_pretrained_bert import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNAyyR6UCMrs"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "#bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ0g9zKxMJo_"
      },
      "source": [
        "'''train_texts, train_labels = list(zip(*map(lambda data: (train_data['Text'], train_data['Label']), train_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda data: (test_data['Text'], test_data['Label']), test_data)))'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr278nE5VNCx",
        "outputId": "9c6b9d24-9f69-43fe-cf92-9a93b4dce841"
      },
      "source": [
        "len(train_txts), len(train_lbels), len(test_txts), len(test_lbels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6r3HMTwDIc1"
      },
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_txts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_txts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5SrS8KBDdpL"
      },
      "source": [
        "'''Convert each token in each news to an id as present in the tokenizer vocabulary. If there’s a \n",
        "   token that is not present in the vocabulary, the tokenizer will use the special [UNK] token and\n",
        "   use its id'''\n",
        "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
        "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJquxvvkEd01"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqxNHaB6ECSj"
      },
      "source": [
        "'''we need to pad our input so it will have the same size of 512. It means that for any review that \n",
        "   is shorter than 512 tokens, we’ll add zeros to reach 512 tokens'''\n",
        "\n",
        "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdfszA6xEmgL"
      },
      "source": [
        "'''Our target variable is currently a list of 0 and 1. We’ll convert it to numpy arrays of\n",
        "   booleans'''\n",
        "\n",
        "train_y = np.array(train_lbels) \n",
        "test_y = np.array(test_lbels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NikuDN8nJKpS",
        "outputId": "c66c15d6-3979-492d-922b-3814b3fd2366"
      },
      "source": [
        "type(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Pd-sBrH8bP"
      },
      "source": [
        "from pytorch_pretrained_bert import BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6yDjLhKFNMS"
      },
      "source": [
        "'''Create our BERT classifier which contains an ‘initialization’ method and a ‘forward’ method that \n",
        "   returns token probabilities'''\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI3oZqwIiUf0",
        "outputId": "861ac4c1-8998-4e74-9e07-8f2dde8f18ba"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Po7G49Amicip",
        "outputId": "c4e9bcf2-1d27-4c64-e51b-37154da083db"
      },
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.0M'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL8RzBiUihnu"
      },
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf = bert_clf.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MWQFsESWinS-",
        "outputId": "86b09e0b-48bf-4937-9e74-4d756cbd2f54"
      },
      "source": [
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'439.065088M'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2P8yJjjitQA",
        "outputId": "5e0e36be-5b21-42e5-802e-313eb2b2d391"
      },
      "source": [
        "x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
        "y, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\n",
        "x.shape, y.shape, pooled.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 512]), torch.Size([3, 512, 768]), torch.Size([3, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SiFydbR9jQJe",
        "outputId": "38d3224a-6d7d-4c34-f9c6-259a74909509"
      },
      "source": [
        "y, x, pooled = None, None, None\n",
        "torch.cuda.empty_cache()\n",
        "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3568.20736M'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_KKqL30grVX"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J3KVeyNIJuv"
      },
      "source": [
        "'''Generate training and testing masks'''\n",
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbPwFNkdIdb9"
      },
      "source": [
        "'''Generate token tensors for training and testing'''\n",
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mLehe6FALf"
      },
      "source": [
        "'''Prepare data loaders'''\n",
        "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
        "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
        "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzicamwpiGLg"
      },
      "source": [
        "param_optimizer = list(bert_clf.sigmoid.named_parameters()) \n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imzDBTwDiRSz"
      },
      "source": [
        "from torch.optim import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq1MBHNSiIWf"
      },
      "source": [
        "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJgnqTONjzp9"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIdRsfeMguTk"
      },
      "source": [
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        loss_func = nn.BCELoss()\n",
        "\n",
        "        batch_loss = loss_func(logits, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        #clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        #clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLZA_4Wuj7YH"
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        loss = loss_func(logits, labels)\n",
        "        numpy_logits = logits.cpu().detach().numpy()\n",
        "        \n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "        all_logits += list(numpy_logits[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiknD7Naj9Np",
        "outputId": "979f143c-b7d1-40d2-d094-d7d1082df299"
      },
      "source": [
        "np.mean(bert_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM79bzmskACi",
        "outputId": "6cca0a0f-007d-4972-d6ef-b6cf2af1f6f2"
      },
      "source": [
        "print(classification_report(test_y, bert_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.90      0.71        39\n",
            "           1       0.90      0.61      0.73        61\n",
            "\n",
            "    accuracy                           0.72       100\n",
            "   macro avg       0.75      0.75      0.72       100\n",
            "weighted avg       0.78      0.72      0.72       100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}